{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom Dataset Format to COCO Format Conversion.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aakarsh7599/Text-Detection-using-Detectron2/blob/master/Custom_Dataset_Format_to_COCO_Format_Conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDGLHTbTrucJ",
        "colab_type": "text"
      },
      "source": [
        "# Conversion of Dataset to COCO Format\n",
        "\n",
        "In this notebook, we'll convert our Custom Dataset format to the COCO Format which can be used to train a model in Detectron2.\n",
        "\n",
        "- This dataset consists of 428 real images in the image folder. Annotation corresponding to image presents in Annotation folder. Out of which **401 images are used for training and the remaining 27 images are used for validation**. \n",
        "- The Annotation for the image has the same name that of the image just with the difference of extension. \n",
        "For example, if the image name is \"1.jpg\" then the corresponding annotation will be \"1.txt\".\n",
        "- The format for the storage of the annotation file is as such.\n",
        "- The no. of the lines in annotation text file denotes no of bounding box present in that image.\n",
        "- A single line represents a single bounding box. format is as follow x1, x2, x3, x4, y1, y2, y3, y4, Language. \n",
        "Where (x1,y1) is the top left, (x2,y2) is top right, (x3,y3) bottom right, (x4,y4) bottom left.\n",
        "- the order of point is in the clockwise order starting from the top-left points.\n",
        "\n",
        "\n",
        "You can download the dataset here: https://drive.google.com/file/d/1gZW8WiQz5UYPXo97nmcP7AI8dHH1yqPM/view?usp=sharing\n",
        "\n",
        "Upload it either to your session storage or upload it to your drive and mount your drive to this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxwi9aqozoPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fe976dcf-c16e-456a-867c-21828f458868"
      },
      "source": [
        "#If you did upload the zip file to your session storage, use this command or else modify accordingly.\n",
        "!unzip \"/content/Text Detection Dataset.zip\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/Text Detection Dataset.zip\n",
            "   creating: Text Detection Dataset/\n",
            "   creating: Text Detection Dataset/Train/\n",
            "   creating: Text Detection Dataset/Train/Annotations/\n",
            "  inflating: Text Detection Dataset/Train/Annotations/0.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/1.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/10.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/100.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/101.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/102.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/103.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/104.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/105.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/106.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/107.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/108.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/109.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/11.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/110.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/111.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/112.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/113.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/114.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/115.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/116.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/117.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/118.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/119.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/12.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/120.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/121.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/122.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/123.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/124.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/125.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/126.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/127.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/128.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/129.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/13.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/130.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/131.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/132.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/133.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/134.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/135.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/136.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/137.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/138.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/139.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/14.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/140.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/141.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/142.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/143.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/144.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/145.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/146.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/147.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/148.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/149.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/15.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/150.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/151.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/152.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/153.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/154.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/155.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/156.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/157.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/158.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/159.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/16.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/160.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/161.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/162.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/163.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/164.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/165.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/166.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/167.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/168.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/169.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/17.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/170.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/171.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/172.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/173.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/174.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/175.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/176.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/177.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/178.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/179.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/18.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/180.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/181.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/182.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/183.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/184.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/185.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/186.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/187.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/188.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/189.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/19.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/190.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/191.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/192.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/193.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/194.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/195.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/196.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/197.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/198.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/199.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/2.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/20.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/200.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/201.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/202.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/203.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/204.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/205.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/206.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/207.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/208.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/209.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/21.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/210.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/211.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/212.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/213.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/214.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/215.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/216.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/217.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/218.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/219.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/22.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/220.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/221.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/222.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/223.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/224.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/225.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/226.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/227.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/228.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/229.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/23.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/230.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/231.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/232.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/233.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/234.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/235.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/236.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/237.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/238.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/239.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/24.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/240.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/241.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/242.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/243.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/244.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/245.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/246.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/247.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/248.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/249.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/25.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/250.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/251.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/252.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/253.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/254.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/255.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/256.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/257.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/258.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/259.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/26.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/260.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/261.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/262.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/263.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/264.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/265.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/266.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/267.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/268.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/269.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/27.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/270.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/271.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/272.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/273.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/274.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/275.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/276.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/277.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/278.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/279.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/28.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/280.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/281.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/282.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/283.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/284.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/285.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/286.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/287.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/288.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/289.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/29.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/290.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/291.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/292.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/293.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/294.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/295.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/296.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/297.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/298.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/299.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/3.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/30.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/300.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/301.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/302.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/303.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/304.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/305.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/306.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/307.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/308.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/309.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/31.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/310.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/311.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/312.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/313.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/314.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/315.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/316.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/317.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/318.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/319.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/32.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/320.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/321.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/322.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/323.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/324.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/325.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/326.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/327.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/328.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/329.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/33.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/330.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/331.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/332.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/333.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/334.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/335.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/336.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/337.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/338.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/339.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/34.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/340.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/341.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/342.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/343.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/344.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/345.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/346.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/347.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/348.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/349.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/35.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/350.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/351.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/352.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/353.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/354.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/355.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/356.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/357.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/358.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/359.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/36.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/360.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/361.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/362.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/363.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/364.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/365.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/366.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/367.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/368.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/369.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/37.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/370.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/371.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/372.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/373.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/374.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/375.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/376.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/377.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/378.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/379.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/38.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/380.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/381.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/382.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/383.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/384.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/385.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/386.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/387.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/388.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/389.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/39.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/390.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/391.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/392.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/393.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/394.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/395.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/396.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/397.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/398.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/399.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/4.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/40.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/400.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/41.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/42.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/43.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/44.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/45.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/46.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/47.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/48.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/49.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/5.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/50.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/51.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/52.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/53.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/54.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/55.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/56.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/57.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/58.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/59.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/6.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/60.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/61.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/62.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/63.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/64.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/65.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/66.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/67.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/68.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/69.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/7.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/70.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/71.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/72.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/73.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/74.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/75.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/76.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/77.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/78.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/79.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/8.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/80.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/81.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/82.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/83.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/84.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/85.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/86.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/87.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/88.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/89.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/9.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/90.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/91.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/92.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/93.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/94.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/95.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/96.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/97.txt  \n",
            "  inflating: Text Detection Dataset/Train/Annotations/98.txt  \n",
            " extracting: Text Detection Dataset/Train/Annotations/99.txt  \n",
            "   creating: Text Detection Dataset/Train/Images/\n",
            "  inflating: Text Detection Dataset/Train/Images/0.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/1.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/10.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/100.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/101.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/102.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/103.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/104.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/105.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/106.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/107.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/108.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/109.jpeg  \n",
            " extracting: Text Detection Dataset/Train/Images/11.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/110.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/111.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/112.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/113.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/114.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/115.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/116.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/117.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/118.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/119.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/12.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/120.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/121.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/122.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/123.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/124.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/125.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/126.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/127.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/128.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/129.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/13.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/130.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/131.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/132.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/133.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/134.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/135.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/136.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/137.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/138.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/139.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/14.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/140.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/141.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/142.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/143.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/144.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/145.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/146.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/147.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/148.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/149.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/15.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/150.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/151.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/152.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/153.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/154.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/155.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/156.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/157.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/158.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/159.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/16.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/160.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/161.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/162.jpeg  \n",
            " extracting: Text Detection Dataset/Train/Images/163.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/164.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/165.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/166.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/167.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/168.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/169.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/17.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/170.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/171.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/172.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/173.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/174.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/175.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/176.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/177.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/178.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/179.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/18.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/180.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/181.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/182.jpeg  \n",
            " extracting: Text Detection Dataset/Train/Images/183.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/184.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/185.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/186.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/187.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/188.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/189.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/19.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/190.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/191.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/192.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/193.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/194.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/195.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/196.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/197.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/198.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/199.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/2.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/20.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/200.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/201.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/202.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/203.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/204.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/205.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/206.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/207.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/208.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/209.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/21.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/210.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/211.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/212.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/213.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/214.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/215.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/216.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/217.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/218.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/219.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/22.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/220.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/221.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/222.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/223.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/224.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/225.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/226.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/227.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/228.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/229.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/23.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/230.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/231.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/232.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/233.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/234.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/235.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/236.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/237.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/238.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/239.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/24.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/240.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/241.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/242.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/243.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/244.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/245.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/246.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/247.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/248.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/249.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/25.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/250.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/251.jpeg  \n",
            " extracting: Text Detection Dataset/Train/Images/252.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/253.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/254.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/255.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/256.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/257.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/258.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/259.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/26.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/260.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/261.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/262.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/263.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/264.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/265.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/266.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/267.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/268.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/269.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/27.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/270.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/271.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/272.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/273.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/274.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/275.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/276.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/277.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/278.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/279.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/28.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/280.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/281.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/282.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/283.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/284.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/285.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/286.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/287.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/288.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/289.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/29.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/290.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/291.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/292.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/293.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/294.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/295.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/296.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/297.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/298.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/299.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/3.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/30.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/300.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/301.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/302.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/303.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/304.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/305.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/306.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/307.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/308.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/309.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/31.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/310.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/311.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/312.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/313.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/314.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/315.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/316.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/317.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/318.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/319.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/32.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/320.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/321.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/322.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/323.jpeg  \n",
            " extracting: Text Detection Dataset/Train/Images/324.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/325.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/326.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/327.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/328.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/329.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/33.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/330.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/331.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/332.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/333.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/334.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/335.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/336.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/337.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/338.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/339.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/34.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/340.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/341.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/342.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/343.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/344.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/345.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/346.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/347.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/348.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/349.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/35.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/350.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/351.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/352.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/353.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/354.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/355.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/356.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/357.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/358.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/359.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/36.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/360.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/361.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/362.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/363.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/364.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/365.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/366.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/367.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/368.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/369.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/37.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/370.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/371.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/372.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/373.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/374.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/375.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/376.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/377.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/378.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/379.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/38.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/380.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/381.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/382.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/383.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/384.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/385.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/386.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/387.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/388.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/389.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/39.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/390.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/391.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/392.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/393.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/394.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/395.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/396.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/397.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/398.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/399.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/4.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/40.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/400.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/41.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/42.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/43.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/44.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/45.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/46.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/47.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/48.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/49.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/5.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/50.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/51.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/52.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/53.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/54.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/55.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/56.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/57.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/58.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/59.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/6.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/60.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/61.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/62.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/63.jpeg  \n",
            " extracting: Text Detection Dataset/Train/Images/64.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/65.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/66.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/67.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/68.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/69.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/7.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/70.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/71.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/72.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/73.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/74.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/75.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/76.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/77.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/78.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/79.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/8.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/80.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/81.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/82.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/83.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/84.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/85.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/86.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/87.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/88.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/89.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/9.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/90.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/91.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/92.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/93.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/94.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/95.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/96.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/97.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/98.jpeg  \n",
            "  inflating: Text Detection Dataset/Train/Images/99.jpeg  \n",
            "   creating: Text Detection Dataset/Val/\n",
            "   creating: Text Detection Dataset/Val/Annotations/\n",
            "  inflating: Text Detection Dataset/Val/Annotations/401.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/402.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/403.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/404.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/405.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/406.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/407.txt  \n",
            " extracting: Text Detection Dataset/Val/Annotations/408.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/409.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/410.txt  \n",
            " extracting: Text Detection Dataset/Val/Annotations/411.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/412.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/413.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/414.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/415.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/416.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/417.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/418.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/419.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/420.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/421.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/422.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/423.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/424.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/425.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/426.txt  \n",
            "  inflating: Text Detection Dataset/Val/Annotations/427.txt  \n",
            "   creating: Text Detection Dataset/Val/Images/\n",
            "  inflating: Text Detection Dataset/Val/Images/401.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/402.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/403.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/404.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/405.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/406.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/407.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/408.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/409.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/410.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/411.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/412.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/413.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/414.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/415.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/416.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/417.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/418.jpeg  \n",
            " extracting: Text Detection Dataset/Val/Images/419.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/420.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/421.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/422.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/423.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/424.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/425.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/426.jpeg  \n",
            "  inflating: Text Detection Dataset/Val/Images/427.jpeg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtLWwkLQL5fA",
        "colab_type": "text"
      },
      "source": [
        "## For Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCEebbg8WYsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqrrNC1P6FiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main_result=pd.DataFrame(columns=[\"file_name\",\"height\",\"width\",\"annotations\"])\n",
        "main_result[\"annotations\"]=main_result[\"annotations\"].astype('object')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V49mmRV8jsT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce7c6a89-8847-423d-d9c5-8c89466112e9"
      },
      "source": [
        "import os\n",
        "from natsort import natsorted\n",
        "os.chdir(\"/content/Text Detection Dataset/Train/Annotations\")\n",
        "file_list =  natsorted(os.listdir())\n",
        "for i in natsorted(os.listdir()):\n",
        "  print(i)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.txt\n",
            "1.txt\n",
            "2.txt\n",
            "3.txt\n",
            "4.txt\n",
            "5.txt\n",
            "6.txt\n",
            "7.txt\n",
            "8.txt\n",
            "9.txt\n",
            "10.txt\n",
            "11.txt\n",
            "12.txt\n",
            "13.txt\n",
            "14.txt\n",
            "15.txt\n",
            "16.txt\n",
            "17.txt\n",
            "18.txt\n",
            "19.txt\n",
            "20.txt\n",
            "21.txt\n",
            "22.txt\n",
            "23.txt\n",
            "24.txt\n",
            "25.txt\n",
            "26.txt\n",
            "27.txt\n",
            "28.txt\n",
            "29.txt\n",
            "30.txt\n",
            "31.txt\n",
            "32.txt\n",
            "33.txt\n",
            "34.txt\n",
            "35.txt\n",
            "36.txt\n",
            "37.txt\n",
            "38.txt\n",
            "39.txt\n",
            "40.txt\n",
            "41.txt\n",
            "42.txt\n",
            "43.txt\n",
            "44.txt\n",
            "45.txt\n",
            "46.txt\n",
            "47.txt\n",
            "48.txt\n",
            "49.txt\n",
            "50.txt\n",
            "51.txt\n",
            "52.txt\n",
            "53.txt\n",
            "54.txt\n",
            "55.txt\n",
            "56.txt\n",
            "57.txt\n",
            "58.txt\n",
            "59.txt\n",
            "60.txt\n",
            "61.txt\n",
            "62.txt\n",
            "63.txt\n",
            "64.txt\n",
            "65.txt\n",
            "66.txt\n",
            "67.txt\n",
            "68.txt\n",
            "69.txt\n",
            "70.txt\n",
            "71.txt\n",
            "72.txt\n",
            "73.txt\n",
            "74.txt\n",
            "75.txt\n",
            "76.txt\n",
            "77.txt\n",
            "78.txt\n",
            "79.txt\n",
            "80.txt\n",
            "81.txt\n",
            "82.txt\n",
            "83.txt\n",
            "84.txt\n",
            "85.txt\n",
            "86.txt\n",
            "87.txt\n",
            "88.txt\n",
            "89.txt\n",
            "90.txt\n",
            "91.txt\n",
            "92.txt\n",
            "93.txt\n",
            "94.txt\n",
            "95.txt\n",
            "96.txt\n",
            "97.txt\n",
            "98.txt\n",
            "99.txt\n",
            "100.txt\n",
            "101.txt\n",
            "102.txt\n",
            "103.txt\n",
            "104.txt\n",
            "105.txt\n",
            "106.txt\n",
            "107.txt\n",
            "108.txt\n",
            "109.txt\n",
            "110.txt\n",
            "111.txt\n",
            "112.txt\n",
            "113.txt\n",
            "114.txt\n",
            "115.txt\n",
            "116.txt\n",
            "117.txt\n",
            "118.txt\n",
            "119.txt\n",
            "120.txt\n",
            "121.txt\n",
            "122.txt\n",
            "123.txt\n",
            "124.txt\n",
            "125.txt\n",
            "126.txt\n",
            "127.txt\n",
            "128.txt\n",
            "129.txt\n",
            "130.txt\n",
            "131.txt\n",
            "132.txt\n",
            "133.txt\n",
            "134.txt\n",
            "135.txt\n",
            "136.txt\n",
            "137.txt\n",
            "138.txt\n",
            "139.txt\n",
            "140.txt\n",
            "141.txt\n",
            "142.txt\n",
            "143.txt\n",
            "144.txt\n",
            "145.txt\n",
            "146.txt\n",
            "147.txt\n",
            "148.txt\n",
            "149.txt\n",
            "150.txt\n",
            "151.txt\n",
            "152.txt\n",
            "153.txt\n",
            "154.txt\n",
            "155.txt\n",
            "156.txt\n",
            "157.txt\n",
            "158.txt\n",
            "159.txt\n",
            "160.txt\n",
            "161.txt\n",
            "162.txt\n",
            "163.txt\n",
            "164.txt\n",
            "165.txt\n",
            "166.txt\n",
            "167.txt\n",
            "168.txt\n",
            "169.txt\n",
            "170.txt\n",
            "171.txt\n",
            "172.txt\n",
            "173.txt\n",
            "174.txt\n",
            "175.txt\n",
            "176.txt\n",
            "177.txt\n",
            "178.txt\n",
            "179.txt\n",
            "180.txt\n",
            "181.txt\n",
            "182.txt\n",
            "183.txt\n",
            "184.txt\n",
            "185.txt\n",
            "186.txt\n",
            "187.txt\n",
            "188.txt\n",
            "189.txt\n",
            "190.txt\n",
            "191.txt\n",
            "192.txt\n",
            "193.txt\n",
            "194.txt\n",
            "195.txt\n",
            "196.txt\n",
            "197.txt\n",
            "198.txt\n",
            "199.txt\n",
            "200.txt\n",
            "201.txt\n",
            "202.txt\n",
            "203.txt\n",
            "204.txt\n",
            "205.txt\n",
            "206.txt\n",
            "207.txt\n",
            "208.txt\n",
            "209.txt\n",
            "210.txt\n",
            "211.txt\n",
            "212.txt\n",
            "213.txt\n",
            "214.txt\n",
            "215.txt\n",
            "216.txt\n",
            "217.txt\n",
            "218.txt\n",
            "219.txt\n",
            "220.txt\n",
            "221.txt\n",
            "222.txt\n",
            "223.txt\n",
            "224.txt\n",
            "225.txt\n",
            "226.txt\n",
            "227.txt\n",
            "228.txt\n",
            "229.txt\n",
            "230.txt\n",
            "231.txt\n",
            "232.txt\n",
            "233.txt\n",
            "234.txt\n",
            "235.txt\n",
            "236.txt\n",
            "237.txt\n",
            "238.txt\n",
            "239.txt\n",
            "240.txt\n",
            "241.txt\n",
            "242.txt\n",
            "243.txt\n",
            "244.txt\n",
            "245.txt\n",
            "246.txt\n",
            "247.txt\n",
            "248.txt\n",
            "249.txt\n",
            "250.txt\n",
            "251.txt\n",
            "252.txt\n",
            "253.txt\n",
            "254.txt\n",
            "255.txt\n",
            "256.txt\n",
            "257.txt\n",
            "258.txt\n",
            "259.txt\n",
            "260.txt\n",
            "261.txt\n",
            "262.txt\n",
            "263.txt\n",
            "264.txt\n",
            "265.txt\n",
            "266.txt\n",
            "267.txt\n",
            "268.txt\n",
            "269.txt\n",
            "270.txt\n",
            "271.txt\n",
            "272.txt\n",
            "273.txt\n",
            "274.txt\n",
            "275.txt\n",
            "276.txt\n",
            "277.txt\n",
            "278.txt\n",
            "279.txt\n",
            "280.txt\n",
            "281.txt\n",
            "282.txt\n",
            "283.txt\n",
            "284.txt\n",
            "285.txt\n",
            "286.txt\n",
            "287.txt\n",
            "288.txt\n",
            "289.txt\n",
            "290.txt\n",
            "291.txt\n",
            "292.txt\n",
            "293.txt\n",
            "294.txt\n",
            "295.txt\n",
            "296.txt\n",
            "297.txt\n",
            "298.txt\n",
            "299.txt\n",
            "300.txt\n",
            "301.txt\n",
            "302.txt\n",
            "303.txt\n",
            "304.txt\n",
            "305.txt\n",
            "306.txt\n",
            "307.txt\n",
            "308.txt\n",
            "309.txt\n",
            "310.txt\n",
            "311.txt\n",
            "312.txt\n",
            "313.txt\n",
            "314.txt\n",
            "315.txt\n",
            "316.txt\n",
            "317.txt\n",
            "318.txt\n",
            "319.txt\n",
            "320.txt\n",
            "321.txt\n",
            "322.txt\n",
            "323.txt\n",
            "324.txt\n",
            "325.txt\n",
            "326.txt\n",
            "327.txt\n",
            "328.txt\n",
            "329.txt\n",
            "330.txt\n",
            "331.txt\n",
            "332.txt\n",
            "333.txt\n",
            "334.txt\n",
            "335.txt\n",
            "336.txt\n",
            "337.txt\n",
            "338.txt\n",
            "339.txt\n",
            "340.txt\n",
            "341.txt\n",
            "342.txt\n",
            "343.txt\n",
            "344.txt\n",
            "345.txt\n",
            "346.txt\n",
            "347.txt\n",
            "348.txt\n",
            "349.txt\n",
            "350.txt\n",
            "351.txt\n",
            "352.txt\n",
            "353.txt\n",
            "354.txt\n",
            "355.txt\n",
            "356.txt\n",
            "357.txt\n",
            "358.txt\n",
            "359.txt\n",
            "360.txt\n",
            "361.txt\n",
            "362.txt\n",
            "363.txt\n",
            "364.txt\n",
            "365.txt\n",
            "366.txt\n",
            "367.txt\n",
            "368.txt\n",
            "369.txt\n",
            "370.txt\n",
            "371.txt\n",
            "372.txt\n",
            "373.txt\n",
            "374.txt\n",
            "375.txt\n",
            "376.txt\n",
            "377.txt\n",
            "378.txt\n",
            "379.txt\n",
            "380.txt\n",
            "381.txt\n",
            "382.txt\n",
            "383.txt\n",
            "384.txt\n",
            "385.txt\n",
            "386.txt\n",
            "387.txt\n",
            "388.txt\n",
            "389.txt\n",
            "390.txt\n",
            "391.txt\n",
            "392.txt\n",
            "393.txt\n",
            "394.txt\n",
            "395.txt\n",
            "396.txt\n",
            "397.txt\n",
            "398.txt\n",
            "399.txt\n",
            "400.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7SsE2KddHuu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0906caca-f95e-49c1-9f79-8fa7f7072c35"
      },
      "source": [
        "cat_dict = {\"HINDI\":\"0\",\"ENGLISH\":\"1\",\"OTHER\":\"2\"}\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "print(file_list)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0.txt', '1.txt', '2.txt', '3.txt', '4.txt', '5.txt', '6.txt', '7.txt', '8.txt', '9.txt', '10.txt', '11.txt', '12.txt', '13.txt', '14.txt', '15.txt', '16.txt', '17.txt', '18.txt', '19.txt', '20.txt', '21.txt', '22.txt', '23.txt', '24.txt', '25.txt', '26.txt', '27.txt', '28.txt', '29.txt', '30.txt', '31.txt', '32.txt', '33.txt', '34.txt', '35.txt', '36.txt', '37.txt', '38.txt', '39.txt', '40.txt', '41.txt', '42.txt', '43.txt', '44.txt', '45.txt', '46.txt', '47.txt', '48.txt', '49.txt', '50.txt', '51.txt', '52.txt', '53.txt', '54.txt', '55.txt', '56.txt', '57.txt', '58.txt', '59.txt', '60.txt', '61.txt', '62.txt', '63.txt', '64.txt', '65.txt', '66.txt', '67.txt', '68.txt', '69.txt', '70.txt', '71.txt', '72.txt', '73.txt', '74.txt', '75.txt', '76.txt', '77.txt', '78.txt', '79.txt', '80.txt', '81.txt', '82.txt', '83.txt', '84.txt', '85.txt', '86.txt', '87.txt', '88.txt', '89.txt', '90.txt', '91.txt', '92.txt', '93.txt', '94.txt', '95.txt', '96.txt', '97.txt', '98.txt', '99.txt', '100.txt', '101.txt', '102.txt', '103.txt', '104.txt', '105.txt', '106.txt', '107.txt', '108.txt', '109.txt', '110.txt', '111.txt', '112.txt', '113.txt', '114.txt', '115.txt', '116.txt', '117.txt', '118.txt', '119.txt', '120.txt', '121.txt', '122.txt', '123.txt', '124.txt', '125.txt', '126.txt', '127.txt', '128.txt', '129.txt', '130.txt', '131.txt', '132.txt', '133.txt', '134.txt', '135.txt', '136.txt', '137.txt', '138.txt', '139.txt', '140.txt', '141.txt', '142.txt', '143.txt', '144.txt', '145.txt', '146.txt', '147.txt', '148.txt', '149.txt', '150.txt', '151.txt', '152.txt', '153.txt', '154.txt', '155.txt', '156.txt', '157.txt', '158.txt', '159.txt', '160.txt', '161.txt', '162.txt', '163.txt', '164.txt', '165.txt', '166.txt', '167.txt', '168.txt', '169.txt', '170.txt', '171.txt', '172.txt', '173.txt', '174.txt', '175.txt', '176.txt', '177.txt', '178.txt', '179.txt', '180.txt', '181.txt', '182.txt', '183.txt', '184.txt', '185.txt', '186.txt', '187.txt', '188.txt', '189.txt', '190.txt', '191.txt', '192.txt', '193.txt', '194.txt', '195.txt', '196.txt', '197.txt', '198.txt', '199.txt', '200.txt', '201.txt', '202.txt', '203.txt', '204.txt', '205.txt', '206.txt', '207.txt', '208.txt', '209.txt', '210.txt', '211.txt', '212.txt', '213.txt', '214.txt', '215.txt', '216.txt', '217.txt', '218.txt', '219.txt', '220.txt', '221.txt', '222.txt', '223.txt', '224.txt', '225.txt', '226.txt', '227.txt', '228.txt', '229.txt', '230.txt', '231.txt', '232.txt', '233.txt', '234.txt', '235.txt', '236.txt', '237.txt', '238.txt', '239.txt', '240.txt', '241.txt', '242.txt', '243.txt', '244.txt', '245.txt', '246.txt', '247.txt', '248.txt', '249.txt', '250.txt', '251.txt', '252.txt', '253.txt', '254.txt', '255.txt', '256.txt', '257.txt', '258.txt', '259.txt', '260.txt', '261.txt', '262.txt', '263.txt', '264.txt', '265.txt', '266.txt', '267.txt', '268.txt', '269.txt', '270.txt', '271.txt', '272.txt', '273.txt', '274.txt', '275.txt', '276.txt', '277.txt', '278.txt', '279.txt', '280.txt', '281.txt', '282.txt', '283.txt', '284.txt', '285.txt', '286.txt', '287.txt', '288.txt', '289.txt', '290.txt', '291.txt', '292.txt', '293.txt', '294.txt', '295.txt', '296.txt', '297.txt', '298.txt', '299.txt', '300.txt', '301.txt', '302.txt', '303.txt', '304.txt', '305.txt', '306.txt', '307.txt', '308.txt', '309.txt', '310.txt', '311.txt', '312.txt', '313.txt', '314.txt', '315.txt', '316.txt', '317.txt', '318.txt', '319.txt', '320.txt', '321.txt', '322.txt', '323.txt', '324.txt', '325.txt', '326.txt', '327.txt', '328.txt', '329.txt', '330.txt', '331.txt', '332.txt', '333.txt', '334.txt', '335.txt', '336.txt', '337.txt', '338.txt', '339.txt', '340.txt', '341.txt', '342.txt', '343.txt', '344.txt', '345.txt', '346.txt', '347.txt', '348.txt', '349.txt', '350.txt', '351.txt', '352.txt', '353.txt', '354.txt', '355.txt', '356.txt', '357.txt', '358.txt', '359.txt', '360.txt', '361.txt', '362.txt', '363.txt', '364.txt', '365.txt', '366.txt', '367.txt', '368.txt', '369.txt', '370.txt', '371.txt', '372.txt', '373.txt', '374.txt', '375.txt', '376.txt', '377.txt', '378.txt', '379.txt', '380.txt', '381.txt', '382.txt', '383.txt', '384.txt', '385.txt', '386.txt', '387.txt', '388.txt', '389.txt', '390.txt', '391.txt', '392.txt', '393.txt', '394.txt', '395.txt', '396.txt', '397.txt', '398.txt', '399.txt', '400.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEmI5vm_Wv9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "header_list = [\"x1\", \"x2\", \"x3\", \"x4\",\"y1\", \"y2\",\"y3\", \"y4\", \"category_id\"]\n",
        "\n",
        "k=0\n",
        "for i in file_list:\n",
        "  df = pd.read_csv(i,header = None,index_col=False,names=header_list)\n",
        "  df[\"height\"] = abs(df[\"y1\"]-df[\"y3\"])\n",
        "  df[\"width\"] = abs(df[\"x1\"]-df[\"x3\"])\n",
        "  df=df[[\"x1\",\"y1\",\"width\",\"height\",\"category_id\"]]\n",
        "  df1=df\n",
        "  \n",
        "  df1[\"bbox\"] = df1.iloc[:,0:4].values.tolist()\n",
        "  df1[\"bbox_mode\"] = 1\n",
        "  df1 = df1.replace({\"category_id\": cat_dict})\n",
        "  df1=df1[[\"bbox\",\t\"bbox_mode\",\t\"category_id\"]]\n",
        "  annotations = df1.T.to_dict().values()\n",
        "  l = []\n",
        "  for j in annotations:\n",
        "    l.append(j)\n",
        "  res=pd.DataFrame(columns=[\"file_name\",\"height\",\"width\",\"annotations\"])\n",
        "  res[\"annotations\"]=res[\"annotations\"].astype('object')\n",
        "  res.at[0,\"file_name\"] = i[:-4]+\".jpeg\"\n",
        "  res.at[0,\"annotations\"] = l\n",
        "  h = cv2.imread(\"../Images/\"+str(k)+\".jpeg\").shape[:2]\n",
        "  res.at[0,\"height\"] = h[0]\n",
        "  res.at[0,\"width\"] = h[1]\n",
        "  k=k+1\n",
        "  main_result = main_result.append(res)\n",
        "  main_result.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi1jp9y2GTOX",
        "colab_type": "text"
      },
      "source": [
        "You'll see the Json file in the annotations folder of train data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7snlRpWL_SpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main_result.reset_index(inplace=True)\n",
        "main_result.rename(columns={\"index\":\"image_id\"},inplace=True)\n",
        "main_result.to_json(\"train.json\",orient=\"records\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX392LYwLxtG",
        "colab_type": "text"
      },
      "source": [
        "## For Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XA8DSATfLaTD",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-98LTYowLaTL",
        "colab": {}
      },
      "source": [
        "main_result=pd.DataFrame(columns=[\"file_name\",\"height\",\"width\",\"annotations\"])\n",
        "main_result[\"annotations\"]=main_result[\"annotations\"].astype('object')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UfL5oblHLaTN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "2f71e27f-3bad-48ad-c230-1282d1a4c13e"
      },
      "source": [
        "import os\n",
        "from natsort import natsorted\n",
        "os.chdir(\"/content/Text Detection Dataset/Val/Annotations\")\n",
        "file_list =  natsorted(os.listdir())\n",
        "for i in natsorted(os.listdir()):\n",
        "  print(i)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "401.txt\n",
            "402.txt\n",
            "403.txt\n",
            "404.txt\n",
            "405.txt\n",
            "406.txt\n",
            "407.txt\n",
            "408.txt\n",
            "409.txt\n",
            "410.txt\n",
            "411.txt\n",
            "412.txt\n",
            "413.txt\n",
            "414.txt\n",
            "415.txt\n",
            "416.txt\n",
            "417.txt\n",
            "418.txt\n",
            "419.txt\n",
            "420.txt\n",
            "421.txt\n",
            "422.txt\n",
            "423.txt\n",
            "424.txt\n",
            "425.txt\n",
            "426.txt\n",
            "427.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bNqhXjBQLaTR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c32abff7-8a68-4797-d216-39c7b853db25"
      },
      "source": [
        "cat_dict = {\"HINDI\":\"0\",\"ENGLISH\":\"1\",\"OTHER\":\"2\"}\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "print(file_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['401.txt', '402.txt', '403.txt', '404.txt', '405.txt', '406.txt', '407.txt', '408.txt', '409.txt', '410.txt', '411.txt', '412.txt', '413.txt', '414.txt', '415.txt', '416.txt', '417.txt', '418.txt', '419.txt', '420.txt', '421.txt', '422.txt', '423.txt', '424.txt', '425.txt', '426.txt', '427.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7z03GNdRLaTT",
        "colab": {}
      },
      "source": [
        "header_list = [\"x1\", \"x2\", \"x3\", \"x4\",\"y1\", \"y2\",\"y3\", \"y4\", \"category_id\"]\n",
        "\n",
        "k=401\n",
        "for i in file_list:\n",
        "  df = pd.read_csv(i,header = None,index_col=False,names=header_list)\n",
        "  df[\"height\"] = abs(df[\"y1\"]-df[\"y3\"])\n",
        "  df[\"width\"] = abs(df[\"x1\"]-df[\"x3\"])\n",
        "  df=df[[\"x1\",\"y1\",\"width\",\"height\",\"category_id\"]]\n",
        "  df1=df\n",
        "  \n",
        "  df1[\"bbox\"] = df1.iloc[:,0:4].values.tolist()\n",
        "  df1[\"bbox_mode\"] = 1\n",
        "  df1 = df1.replace({\"category_id\": cat_dict})\n",
        "  df1=df1[[\"bbox\",\t\"bbox_mode\",\t\"category_id\"]]\n",
        "  annotations = df1.T.to_dict().values()\n",
        "  l = []\n",
        "  for j in annotations:\n",
        "    l.append(j)\n",
        "  res=pd.DataFrame(columns=[\"file_name\",\"height\",\"width\",\"annotations\"])\n",
        "  res[\"annotations\"]=res[\"annotations\"].astype('object')\n",
        "  res.at[0,\"file_name\"] = i[:-4] + \".jpeg\"\n",
        "  res.at[0,\"annotations\"] = l\n",
        "  h = cv2.imread(\"../Images/\"+str(k)+\".jpeg\").shape[:2]\n",
        "  res.at[0,\"height\"] = h[0]\n",
        "  res.at[0,\"width\"] = h[1]\n",
        "  k=k+1\n",
        "  main_result = main_result.append(res)\n",
        "  main_result.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wxYWW1RRLaTW",
        "colab": {}
      },
      "source": [
        "\n",
        "main_result.reset_index(inplace=True)\n",
        "main_result.rename(columns={\"index\":\"image_id\"},inplace=True)\n",
        "main_result.to_json(\"val.json\",orient=\"records\")"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}